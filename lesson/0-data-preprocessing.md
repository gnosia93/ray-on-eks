LLM을 학습시키기 전 데이터 전처리는 모델의 성능을 결정짓는 핵심 단계입니다. 하지만 프리 트레이닝과 파인 튜닝은 목적이 다른 만큼 전처리 방식에도 차이가 있습니다. 

### 1. 프리 트레이닝(Pre-training) 전처리 ###
방대한 양의 비구조화 데이터에서 일반적인 지식을 학습할 수 있게 정제하는 데 집중합니다. 
* 데이터 클리닝: HTML 태그, 광고성 텍스트, 무의미한 특수문자를 제거하고 중복된 문서를 필터링합니다.
* 독성 제거: 혐오 표현이나 비윤리적인 내용을 사전에 탐지하여 제외합니다.
* 토크나이징: 텍스트를 모델이 이해할 수 있는 숫자(토큰) 단위로 쪼개고, Byte Pair Encoding(BPE) 등을 사용해 어휘 사전을 구축합니다. 

### 2. 파인 튜닝(Fine-tuning) 전처리 ###
특정 목적(예: 챗봇, 요약)에 맞게 구조화된 데이터를 만드는 것이 핵심입니다. 
* 데이터 포맷팅: [Instruction] - [Input] - [Output]과 같은 특정 템플릿에 맞춰 데이터를 재구성합니다.
* 품질 관리: 데이터 양보다는 '정답(Label)'의 정확도가 중요하므로, 사람이 직접 검수하거나 고품질의 합성 데이터를 생성합니다.
* 특수 토큰 추가: 시스템 메시지나 사용자/어시스턴트 역할을 구분하기 위한 특수 토큰을 삽입하여 대화 맥락을 이해시킵니다. 
